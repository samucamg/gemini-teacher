# -*- coding: utf-8 -*-

# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from websockets.legacy.client import WebSocketClientProtocol
from websockets_proxy import Proxy, proxy_connect
import asyncio
import base64
import json
import os
import sys
import pyaudio
from rich.console import Console
from rich.markdown import Markdown
from websockets.asyncio.client import connect
from websockets.asyncio.connection import Connection
from elevenlabs import ElevenLabs, play
import numpy as np
import dotenv

dotenv.load_dotenv()

# Configura√ß√£o b√°sica
FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 16000
CHUNK_SIZE = 512

host = "generativelanguage.googleapis.com"
model = "gemini-2.0-flash-exp"
api_key = os.environ["GOOGLE_API_KEY"]
uri = f"wss://{host}/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent?key={api_key}"

# Configura√ß√µes de voz
pya = pyaudio.PyAudio()
voice_api_key = os.environ.get("ELEVENLABS_API_KEY")
voice_model = "eleven_flash_v2_5"
voice_voice_id = "nPczCjzI2devNBz1zQrb"

# Defini√ß√µes de tema e cena
THEMES = {
    "business": ["job interview", "business meeting", "presentation", "networking"],
    "travel": ["airport", "hotel", "restaurant", "sightseeing"],
    "daily life": ["shopping", "weather", "hobbies", "family"],
    "social": ["meeting friends", "party", "social media", "dating"],
}

class AudioLoop:
    def __init__(self):
        self.ws: WebSocketClientProtocol | Connection
        self.audio_out_queue = asyncio.Queue()
        self.running_step = 0
        self.paused = False
        self.current_theme = None
        self.current_scenario = None
        self.console = Console()
        self.voice_client = None
        
       # Inicializar o cliente de voz
        if voice_api_key:
            self.console.print("Ativar modo de voz", style="green")
            self.voice_client = ElevenLabs(api_key=voice_api_key)
        else:
            self.console.print("Modo de voz desativado, n√£o consigo encontrar ELEVENLABS_API_KEY", style="red")

    def calculate_pronunciation_score(self, audio_data):
        """Calculando pontua√ß√µes de pron√∫ncia"""
        try:
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            
            # Recursos de √°udio de computa√ß√£o
            energy = np.mean(np.abs(audio_array))
            zero_crossings = np.sum(np.abs(np.diff(np.signbit(audio_array))))
            
            # Normalizar e calcular a pontua√ß√£o
            energy_score = min(100, energy / 1000)
            rhythm_score = min(100, zero_crossings / 100)
            
            # Pontua√ß√£o final
            final_score = int(0.6 * energy_score + 0.4 * rhythm_score)
            return min(100, max(0, final_score))
        except Exception as e:
            self.console.print(f"Erro de c√°lculo de classifica√ß√£o: {e}", style="red")
            return 70  # Retorna a pontua√ß√£o padr√£o em caso de erro

    async def startup(self):
     """Inicializar a conversa"""
     # Configurar configura√ß√£o inicial
        setup_msg = {
            "setup": {
                "model": f"models/{model}",
                "generation_config": {"response_modalities": ["TEXT"]},
            }
        }
        await self.ws.send(json.dumps(setup_msg))
        await self.ws.recv()

        # Enviar prompt inicial
        initial_msg = {
            "client_content": {
                "turns": [
                    {
                        "role": "user",
                        "parts": [
                            {
                                "text": """Voc√™ √© um professor de de ingl√™s acostumado a ensinar pron√∫ncia para brasileiros. Por favor, responda em portugu√™s brasileiro e ingl√™s, com ingl√™s primeiro e portugu√™s por √∫ltimo, separados por ---.
                                
                                
Your responsibilities are:
1. Help users correct grammar and pronunciation
2. Give pronunciation scores and detailed feedback
3. Understand and respond to control commands:
   - Pause when user says "Can I have a break"
   - Continue when user says "OK let's continue"
4. Provide practice sentences based on chosen themes and scenarios

Suas responsabilidades s√£o:
1. Ajude os usu√°rios a corrigir a gram√°tica e a pron√∫ncia
2. D√™ classifica√ß√µes de pron√∫ncia e feedback detalhado
3. Entenda e responda √†s instru√ß√µes de controle do usu√°rio:
 - Pausa quando o usu√°rio diz "Posso fazer uma pausa"
 - Continue quando o usu√°rio disser "OK, vamos continuar"
4. Forne√ßa frases de pr√°tica com base em t√≥picos e cen√°rios selecionados

First, ask which theme they want to practice (business, travel, daily life, social) in English.

Cada vez que o usu√°rio termina uma frase, voc√™ precisa:
1. Identifique o que o usu√°rio disse (Ingl√™s)
2. D√™ uma pontua√ß√£o de pron√∫ncia (0-100 pontos)
3. Explica√ß√£o detalhada de problemas de pron√∫ncia e gram√°tica (em portugu√™s e ingl√™s)
4. Forne√ßa sugest√µes de melhoria (em portugu√™s e ingl√™s)
5. Forne√ßa frases de pr√°tica para o pr√≥ximo cen√°rio relevante (em portugu√™s e ingl√™s)

Por favor, mantenha sempre o seguinte formato:
[Conte√∫do em ingl√™s]
---
[Conte√∫do Portugu√™s]

Se voc√™ entendeu, por favor responda em portugu√™s ou ingl√™s. OK"""
                            }
                        ],
                    }
                ],
                "turn_complete": True,
            }
        }
        await self.ws.send(json.dumps(initial_msg))
        
        # Aguarde a resposta da IA OK
        current_response = []
        async for raw_response in self.ws:
            response = json.loads(raw_response)
            try:
                if "serverContent" in response:
                    parts = response["serverContent"].get("modelTurn", {}).get("parts", [])
                    for part in parts:
                        if "text" in part:
                            current_response.append(part["text"])
            except Exception:
                pass

            try:
                turn_complete = response["serverContent"]["turnComplete"]
                if turn_complete:
                    if "".join(current_response).startswith("OK"):
                        self.console.print("Inicializa√ß√£o conclu√≠da ‚úÖ", style="green")
                        return
            except KeyError:
                pass

    async def listen_audio(self):
        """Monitorar entrada de √°udio"""
        mic_info = pya.get_default_input_device_info()
        stream = pya.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )

        self.console.print("üé§ Por favor, fale Ingl√™s", style="yellow")

        while True:
            if self.paused:
                await asyncio.sleep(0.1)
                continue

            data = await asyncio.to_thread(stream.read, CHUNK_SIZE)
            if self.running_step > 1:
                continue

            # Detec√ß√£o de volume
            audio_data = []
            for i in range(0, len(data), 2):
                sample = int.from_bytes(data[i:i+2], byteorder="little", signed=True)
                audio_data.append(abs(sample))
            volume = sum(audio_data) / len(audio_data)

            if volume > 200:
                if self.running_step == 0:
                    self.console.print("üé§ :", style="yellow", end="")
                    self.running_step += 1
                self.console.print("*", style="green", end="")
            await self.audio_out_queue.put(data)

    async def send_audio(self):
        """Enviar dados de √°udio"""
        while True:
            if self.paused:
                await asyncio.sleep(0.1)
                continue

            chunk = await self.audio_out_queue.get()
            msg = {
                "realtime_input": {
                    "media_chunks": [
                        {
                            "data": base64.b64encode(chunk).decode(),
                            "mime_type": "audio/pcm",
                        }
                    ]
                }
            }
            await self.ws.send(json.dumps(msg))

    async def receive_audio(self):
        """Receber e processar respostas"""
        current_response = []
        async for raw_response in self.ws:
            if self.running_step == 1:
                self.console.print("\n‚ôªÔ∏è ProcessamentoÔºö", end="")
                self.running_step += 1

            response = json.loads(raw_response)
            try:
                if "serverContent" in response:
                    parts = response["serverContent"].get("modelTurn", {}).get("parts", [])
                    for part in parts:
                        if "text" in part:
                            current_response.append(part["text"])
                            self.console.print("-", style="blue", end="")
            except Exception:
                pass

            try:
                turn_complete = response["serverContent"]["turnComplete"]
                if turn_complete and current_response:
                    text = "".join(current_response)
                    
                    # Verifique se √© um comando de controle
                    if "can i have a break" in text.lower():
                        self.paused = True
                        self.console.print("\n‚è∏Ô∏è A sess√£o est√° pausada. Diga 'OK, vamos continuar', style="yellow")
                    elif "ok let's continue" in text.lower() and self.paused:
                        self.paused = False
                        self.console.print("\n‚ñ∂Ô∏è Continua√ß√£o da sess√£o", style="green")
                    
                   # Exibir a resposta
                    self.console.print("\nü§ñ =============================================", style="yellow")
                    self.console.print(Markdown(text))
                    
                   # Reproduzir √°udio
                    if self.voice_client and not self.paused:
                        try:
                            def play_audio():
                                # Conte√∫do dividido em chin√™s e ingl√™s
                                parts = text.split('---')
                                if len(parts) > 0:
                                    # Toque apenas a parte em ingl√™s (a primeira parte)
                                    english_text = parts[0].strip()
                                    voice_stream = self.voice_client.text_to_speech.convert_as_stream(
                                        voice_id=voice_voice_id,
                                        text=english_text,
                                        model_id=voice_model,
                                    )
                                    play(voice_stream)

                            self.console.print("üôé Som tocando........", style="yellow")
                            await asyncio.to_thread(play_audio)
                            self.console.print("üôé Reprodu√ß√£o conclu√≠da", style="green")
                        except Exception as e:
                            self.console.print(f"Erro de reprodu√ß√£o de voz: {e}", style="red")

                    current_response = []
                    self.running_step = 0 if not self.paused else 2
            except KeyError:
                pass

    async def run(self):
        """Fun√ß√£o principal em execu√ß√£o"""
        proxy = Proxy.from_url(os.environ["HTTP_PROXY"]) if os.environ.get("HTTP_PROXY") else None
        if proxy:
            self.console.print("Use um proxy", style="yellow")
        else:
            self.console.print("Sem proxy", style="yellow")

        async with (proxy_connect(uri, proxy=proxy) if proxy else connect(uri)) as ws:
            self.ws = ws
            self.console.print("Gemini Assistente de Fala Ingl√™s", style="green", highlight=True)
            self.console.print("Make by twitter: @BoxMrChen", style="blue")
            self.console.print("============================================", style="yellow")
            
            await self.startup()

            async with asyncio.TaskGroup() as tg:
                tg.create_task(self.listen_audio())
                tg.create_task(self.send_audio())
                tg.create_task(self.receive_audio())

                def check_error(task):
                    if task.cancelled():
                        return
                    if task.exception():
                        print(f"Error: {task.exception()}")
                        sys.exit(1)

                for task in tg._tasks:
                    task.add_done_callback(check_error)

if __name__ == "__main__":
    main = AudioLoop()
    asyncio.run(main.run())
