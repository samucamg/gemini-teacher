# -*- coding: utf-8 -*-

# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from websockets.legacy.client import WebSocketClientProtocol
from websockets_proxy import Proxy, proxy_connect
import asyncio
import base64
import json
import os
import sys
import pyaudio
from rich.console import Console
from rich.markdown import Markdown
from websockets.asyncio.client import connect
from websockets.asyncio.connection import Connection
from elevenlabs import ElevenLabs, play
import numpy as np
import dotenv

dotenv.load_dotenv()

# ConfiguraÃ§Ã£o bÃ¡sica
FORMAT = pyaudio.paInt16
CHANNELS = 1
SEND_SAMPLE_RATE = 16000
RECEIVE_SAMPLE_RATE = 16000
CHUNK_SIZE = 512

host = "generativelanguage.googleapis.com"
model = "gemini-2.0-flash-exp"
api_key = os.environ["GOOGLE_API_KEY"]
uri = f"wss://{host}/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent?key={api_key}"

# ConfiguraÃ§Ãµes de voz
pya = pyaudio.PyAudio()
voice_api_key = os.environ.get("ELEVENLABS_API_KEY")
voice_model = "eleven_flash_v2_5"
voice_voice_id = "nPczCjzI2devNBz1zQrb"

# DefiniÃ§Ãµes de tema e cena
THEMES = {
    "business": ["job interview", "business meeting", "presentation", "networking"],
    "travel": ["airport", "hotel", "restaurant", "sightseeing"],
    "daily life": ["shopping", "weather", "hobbies", "family"],
    "social": ["meeting friends", "party", "social media", "dating"],
}

class AudioLoop:
    def __init__(self):
        self.ws: WebSocketClientProtocol | Connection
        self.audio_out_queue = asyncio.Queue()
        self.running_step = 0
        self.paused = False
        self.current_theme = None
        self.current_scenario = None
        self.console = Console()
        self.voice_client = None
        
       # Inicializar o cliente de voz
        if voice_api_key:
            self.console.print("Ativar modo de voz", style="green")
            self.voice_client = ElevenLabs(api_key=voice_api_key)
        else:
            self.console.print("Modo de voz desativado, nÃ£o consigo encontrar ELEVENLABS_API_KEY", style="red")

    def calculate_pronunciation_score(self, audio_data):
        """Calculando pontuaÃ§Ãµes de pronÃºncia"""
        try:
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            
            # Recursos de Ã¡udio de computaÃ§Ã£o
            energy = np.mean(np.abs(audio_array))
            zero_crossings = np.sum(np.abs(np.diff(np.signbit(audio_array))))
            
            # Normalizar e calcular a pontuaÃ§Ã£o
            energy_score = min(100, energy / 1000)
            rhythm_score = min(100, zero_crossings / 100)
            
            # PontuaÃ§Ã£o final
            final_score = int(0.6 * energy_score + 0.4 * rhythm_score)
            return min(100, max(0, final_score))
        except Exception as e:
            self.console.print(f"Erro de cÃ¡lculo de classificaÃ§Ã£o: {e}", style="red")
            return 70  # Retorna a pontuaÃ§Ã£o padrÃ£o em caso de erro

    async def startup(self):
     """Inicializar a conversa"""
     # Configurar configuraÃ§Ã£o inicial
        setup_msg = {
            "setup": {
                "model": f"models/{model}",
                "generation_config": {"response_modalities": ["TEXT"]},
            }
        }
        await self.ws.send(json.dumps(setup_msg))
        await self.ws.recv()

        # Enviar prompt inicial
        initial_msg = {
            "client_content": {
                "turns": [
                    {
                        "role": "user",
                        "parts": [
                            {
                                "text": """VocÃª Ã© um professor de de inglÃªs acostumado a ensinar pronÃºncia para brasileiros. Por favor, responda em portuguÃªs brasileiro e inglÃªs, com inglÃªs primeiro e portuguÃªs por Ãºltimo, separados por ---.
                                
                                
Your responsibilities are:
1. Help users correct grammar and pronunciation
2. Give pronunciation scores and detailed feedback
3. Understand and respond to control commands:
   - Pause when user says "Can I have a break"
   - Continue when user says "OK let's continue"
4. Provide practice sentences based on chosen themes and scenarios

Suas responsabilidades sÃ£o:
1. Ajude os usuÃ¡rios a corrigir a gramÃ¡tica e a pronÃºncia
2. DÃª classificaÃ§Ãµes de pronÃºncia e feedback detalhado
3. Entenda e responda Ã s instruÃ§Ãµes de controle do usuÃ¡rio:
 - Pausa quando o usuÃ¡rio diz "Posso fazer uma pausa"
 - Continue quando o usuÃ¡rio disser "OK, vamos continuar"
4. ForneÃ§a frases de prÃ¡tica com base em tÃ³picos e cenÃ¡rios selecionados

First, ask which theme they want to practice (business, travel, daily life, social) in English.

Cada vez que o usuÃ¡rio termina uma frase, vocÃª precisa:
1. Identifique o que o usuÃ¡rio disse (InglÃªs)
2. DÃª uma pontuaÃ§Ã£o de pronÃºncia (0-100 pontos)
3. ExplicaÃ§Ã£o detalhada de problemas de pronÃºncia e gramÃ¡tica (em portuguÃªs e inglÃªs)
4. ForneÃ§a sugestÃµes de melhoria (em portuguÃªs e inglÃªs)
5. ForneÃ§a frases de prÃ¡tica para o prÃ³ximo cenÃ¡rio relevante (em portuguÃªs e inglÃªs)

Por favor, mantenha sempre o seguinte formato:
[ConteÃºdo em inglÃªs]
---
[ConteÃºdo PortuguÃªs]

Se vocÃª entendeu, por favor responda em portuguÃªs ou inglÃªs. OK"""
                            }
                        ],
                    }
                ],
                "turn_complete": True,
            }
        }
        await self.ws.send(json.dumps(initial_msg))
        
        # Aguarde a resposta da IA OK
        current_response = []
        async for raw_response in self.ws:
            response = json.loads(raw_response)
            try:
                if "serverContent" in response:
                    parts = response["serverContent"].get("modelTurn", {}).get("parts", [])
                    for part in parts:
                        if "text" in part:
                            current_response.append(part["text"])
            except Exception:
                pass

            try:
                turn_complete = response["serverContent"]["turnComplete"]
                if turn_complete:
                    if "".join(current_response).startswith("OK"):
                        self.console.print("InicializaÃ§Ã£o concluÃ­da âœ…", style="green")
                        return
            except KeyError:
                pass

    async def listen_audio(self):
        """Monitorar entrada de Ã¡udio"""
        mic_info = pya.get_default_input_device_info()
        stream = pya.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=SEND_SAMPLE_RATE,
            input=True,
            input_device_index=mic_info["index"],
            frames_per_buffer=CHUNK_SIZE,
        )

        self.console.print("ðŸŽ¤ Por favor, fale InglÃªs", style="yellow")

        while True:
            if self.paused:
                await asyncio.sleep(0.1)
                continue

            data = await asyncio.to_thread(stream.read, CHUNK_SIZE)
            if self.running_step > 1:
                continue

            # DetecÃ§Ã£o de volume
            audio_data = []
            for i in range(0, len(data), 2):
                sample = int.from_bytes(data[i:i+2], byteorder="little", signed=True)
                audio_data.append(abs(sample))
            volume = sum(audio_data) / len(audio_data)

            if volume > 200:
                if self.running_step == 0:
                    self.console.print("ðŸŽ¤ :", style="yellow", end="")
                    self.running_step += 1
                self.console.print("*", style="green", end="")
            await self.audio_out_queue.put(data)

    async def send_audio(self):
        """Enviar dados de Ã¡udio"""
        while True:
            if self.paused:
                await asyncio.sleep(0.1)
                continue

            chunk = await self.audio_out_queue.get()
            msg = {
                "realtime_input": {
                    "media_chunks": [
                        {
                            "data": base64.b64encode(chunk).decode(),
                            "mime_type": "audio/pcm",
                        }
                    ]
                }
            }
            await self.ws.send(json.dumps(msg))

    async def receive_audio(self):
        """Receber e processar respostas"""
        current_response = []
        async for raw_response in self.ws:
            if self.running_step == 1:
                self.console.print("\nâ™»ï¸ Processamentoï¼š", end="")
                self.running_step += 1

            response = json.loads(raw_response)
            try:
                if "serverContent" in response:
                    parts = response["serverContent"].get("modelTurn", {}).get("parts", [])
                    for part in parts:
                        if "text" in part:
                            current_response.append(part["text"])
                            self.console.print("-", style="blue", end="")
            except Exception:
                pass

            try:
                turn_complete = response["serverContent"]["turnComplete"]
                if turn_complete and current_response:
                    text = "".join(current_response)
                    
                    # Verifique se Ã© um comando de controle
                    if "can i have a break" in text.lower():
                        self.paused = True
                        self.console.print("\nâ¸ï¸ A sessÃ£o estÃ¡ pausada. Diga 'OK, vamos continuar', style="yellow")
                    elif "ok let's continue" in text.lower() and self.paused:
                        self.paused = False
                        self.console.print("\nâ–¶ï¸ ContinuaÃ§Ã£o da sessÃ£o", style="green")
                    
                   # Exibir a resposta
                    self.console.print("\nðŸ¤– =============================================", style="yellow")
                    self.console.print(Markdown(text))
                    
                   # Reproduzir Ã¡udio
                    if self.voice_client and not self.paused:
                        try:
                            def play_audio():
                                # ConteÃºdo dividido em chinÃªs e inglÃªs
                                parts = text.split('---')
                                if len(parts) > 0:
                                    # Toque apenas a parte em inglÃªs (a primeira parte)
                                    english_text = parts[0].strip()
                                    voice_stream = self.voice_client.text_to_speech.convert_as_stream(
                                        voice_id=voice_voice_id,
                                        text=english_text,
                                        model_id=voice_model,
                                    )
                                    play(voice_stream)

                            self.console.print("ðŸ™Ž Som tocando........", style="yellow")
                            await asyncio.to_thread(play_audio)
                            self.console.print("ðŸ™Ž ReproduÃ§Ã£o concluÃ­da", style="green")
                        except Exception as e:
                            self.console.print(f"Erro de reproduÃ§Ã£o de voz: {e}", style="red")

                    current_response = []
                    self.running_step = 0 if not self.paused else 2
            except KeyError:
                pass

    async def run(self):
        """FunÃ§Ã£o principal em execuÃ§Ã£o"""
        proxy = Proxy.from_url(os.environ["HTTP_PROXY"]) if os.environ.get("HTTP_PROXY") else None
        if proxy:
            self.console.print("Use um proxy", style="yellow")
        else:
            self.console.print("Sem proxy", style="yellow")

        async with (proxy_connect(uri, proxy=proxy) if proxy else connect(uri)) as ws:
            self.ws = ws
            self.console.print("Gemini Assistente de Fala InglÃªs", style="green", highlight=True)
            self.console.print("Make by twitter: @BoxMrChen", style="blue")
            self.console.print("============================================", style="yellow")
            
            await self.startup()

            async with asyncio.TaskGroup() as tg:
                tg.create_task(self.listen_audio())
                tg.create_task(self.send_audio())
                tg.create_task(self.receive_audio())

                def check_error(task):
                    if task.cancelled():
                        return
                    if task.exception():
                        print(f"Error: {task.exception()}")
                        sys.exit(1)

                for task in tg._tasks:
                    task.add_done_callback(check_error)

if __name__ == "__main__":
    main = AudioLoop()
    asyncio.run(main.run())
